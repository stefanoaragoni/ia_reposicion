{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad De Reposición\n",
    "#### Stefano Aragoni - 20261\n",
    "\n",
    "En este Jupyter Notebook se busca poder analizar y explorar un dataset que contiene información médica de pacientes. Esto con el propósito de determinar, a través de un modelo de regresión logística polinomial, si un paciente si un paciente tendrá o no un paro cardiaco. \n",
    "\n",
    "_______________\n",
    "\n",
    "## Tarea 1.1\n",
    "#### Leer el archivo CSV proporcionado y almacenarlo en un np.array para ser trabajado en el notebook.\n",
    "\n",
    "Como primer paso, se importaron las librerías a utilizar para el respectivo análisis y creación de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, justo como indican las instrucciones, se leyó el archivo CSV y se almacenó en un dataset de pandas. (En las instrucciones decía np.array pero Alberto dijo que con Pandas estaba bien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar dataset\n",
    "dataset = pd.read_csv('framingham.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, se realizó un pequeño análisis exploratorio para determinar si hacen falta datos y si los datos en sí están balanceados. Asimismo, se analizó las mejores variables para crear el respectivo modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos Faltantes\n",
    "Como se puede observar a continuación, sí existen unos datos faltantes. Por tal razón, se rellenará dichos espacios con el promedio del feature. \n",
    "> Usar el promedio puede presentar problemas, sin embargo, no es viable borrar todos los datos debido a que sería más del 5% de las filas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "education          105\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de datos faltantes con np.array\n",
    "missing_values = np.array(dataset.isnull())\n",
    "\n",
    "# Mostrar columnas con datos faltantes \n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "education          0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar SKLearn para reemplazar los datos faltantes\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(dataset.iloc[:, 0:15])\n",
    "dataset.iloc[:, 0:15] = imputer.transform(dataset.iloc[:, 0:15])\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanceo\n",
    "Posteriormente, se determinó si los datos estaban balanceados. En este caso, como se puede observar, sí se cuenta con 644 paros cardiacos vs 3594 no paros cardiacos. Por tal razón, se prosiguió a balancear los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de paros cardiacos: 644\n",
      "Número de no paros cardiacos: 3594\n"
     ]
    }
   ],
   "source": [
    "#Calcular cuantas columans son paro y cuales no\n",
    "print('Número de paros cardiacos:',dataset[dataset['TenYearCHD'] == 1].shape[0])\n",
    "print('Número de no paros cardiacos:',dataset[dataset['TenYearCHD'] == 0].shape[0])\n",
    "data2 = dataset.dropna(subset=['TenYearCHD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de paros cardiacos balanceados: 3594\n",
      "Número de no paros cardiacos balanceados: 3594\n"
     ]
    }
   ],
   "source": [
    "# Separar las características y la variable objetivo\n",
    "X_temp = data2.drop('TenYearCHD', axis=1)\n",
    "y_temp = data2['TenYearCHD']\n",
    "\n",
    "#Aplicar SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_temp, y_temp)\n",
    "\n",
    "dataset2 = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "print('Número de paros cardiacos balanceados:',dataset2[dataset2['TenYearCHD'] == 1].shape[0])\n",
    "print('Número de no paros cardiacos balanceados:',dataset2[dataset2['TenYearCHD'] == 0].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Escalar\n",
    "En este caso, se utilizó la librería de SKLearn para poder escalar los datos. Esto con el propósito de tener datos en un rango de valores similares para que sea más fácil el análisis de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149406</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.277024</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.104520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.319680</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234295</td>\n",
       "      <td>0.208038</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.237518</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200340</td>\n",
       "      <td>0.314421</td>\n",
       "      <td>0.497354</td>\n",
       "      <td>0.316045</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302207</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0   1.0  0.184211   1.000000            0.0    0.000000     0.0   \n",
       "1   0.0  0.368421   0.333333            0.0    0.000000     0.0   \n",
       "2   1.0  0.421053   0.000000            1.0    0.285714     0.0   \n",
       "3   0.0  0.763158   0.666667            1.0    0.428571     0.0   \n",
       "4   0.0  0.368421   0.666667            1.0    0.328571     0.0   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0              0.0           0.0       0.0  0.149406  0.106383  0.232804   \n",
       "1              0.0           0.0       0.0  0.242784  0.177305  0.349206   \n",
       "2              0.0           0.0       0.0  0.234295  0.208038  0.338624   \n",
       "3              0.0           1.0       0.0  0.200340  0.314421  0.497354   \n",
       "4              0.0           0.0       0.0  0.302207  0.219858  0.380952   \n",
       "\n",
       "        BMI  heartRate   glucose  TenYearCHD  \n",
       "0  0.277024   0.363636  0.104520         0.0  \n",
       "1  0.319680   0.515152  0.101695         0.0  \n",
       "2  0.237518   0.313131  0.084746         0.0  \n",
       "3  0.316045   0.212121  0.177966         1.0  \n",
       "4  0.183228   0.414141  0.127119         0.0  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(dataset2)\n",
    "df_feat = pd.DataFrame(scaled_features, columns=dataset2.columns)\n",
    "df_feat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selección de Variables\n",
    "\n",
    "Finalmente, se quiso determinar los features que se estarían utilizando para la realización del modelo. En este caso, se seleccionaron las variables con mayor correlación con TenYearCHD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenYearCHD         1.000000\n",
      "age                0.326011\n",
      "sysBP              0.276992\n",
      "prevalentHyp       0.243732\n",
      "diaBP              0.201807\n",
      "male               0.113976\n",
      "glucose            0.113912\n",
      "BPMeds             0.111842\n",
      "totChol            0.108644\n",
      "BMI                0.106629\n",
      "diabetes           0.084914\n",
      "prevalentStroke    0.075123\n",
      "education          0.073690\n",
      "cigsPerDay         0.053814\n",
      "heartRate          0.028201\n",
      "currentSmoker      0.009025\n",
      "Name: TenYearCHD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Correlación entre las columnas y el status, valores absolutos\n",
    "corr = df_feat.corr()['TenYearCHD'].abs().sort_values(ascending=False)\n",
    "print(corr)\n",
    "\n",
    "# Elegir variables con correlación mayor a 0.1. \n",
    "corr = corr[corr > 0.1]\n",
    "\n",
    "# Crear un nuevo dataframe con las variables seleccionadas\n",
    "df_feat = df_feat[corr.index]\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df_feat.drop('TenYearCHD', axis=1)\n",
    "y = df_feat['TenYearCHD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## Tarea 1.2\n",
    "#### Ajustar un modelo logístico polinomial en base al juego de datos cargado de forma matricial que relaciona las variables independientes que usted considere apropiadas (puede no utilizar todas las componentes de X), con la variable dependiente de salida (sufre o no sufre un paro cardíaco).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se creó primero (a través de PolynomialFeatures) la primera parte del modelo polinomial donde se indica el grado 2 (cuadrático). Posteriormente, se separaron los datos en entrenamiento (80%) y prueba (20%). En base a esto, se presenta la matriz de confusión y el accuracy. \n",
    "\n",
    "En este caso, se presenta un accuracy de 74%. Ya que no es perfecto, no se corre el riesgo de overfitting.\n",
    "\n",
    "Cabe destacar que se creó el modelo sin realizar balanceo, ni scaling. Se obtuvo un peor accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:  [[590 162]\n",
      " [203 483]]\n",
      "Accuracy del modelo: 0.7461752433936022\n"
     ]
    }
   ],
   "source": [
    "# Modelo logistico polinomial\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "print('Matriz de confusión: ', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calcular la accuracy del modelo\n",
    "print('Accuracy del modelo:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## Tarea 1.3\n",
    "#### Utilice la implementación vectorial del algoritmo de regresión logística (descenso del gradiente visto en clase)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se hizo uso de SGDClassifier que permite realizar una regresión logística utilizando el descenso de gradiente. Cabe destacar que se obtuvo un accuracy bastante similar al modelo anterior, así confirmando el procedimiento actualmente realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:  [[584 168]\n",
      " [198 488]]\n",
      "Accuracy del modelo: 0.7454798331015299\n"
     ]
    }
   ],
   "source": [
    "# Descenso de gradiente. \n",
    "# SGDClassifier tiene como parámetro loss='log_loss' para regresión logística. Implementa descenso de gradiente estocástico.\n",
    "sgd = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3)\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('Matriz de confusión: ', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calcular la accuracy del modelo\n",
    "print('Accuracy del modelo:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## Tarea 1.4 \n",
    "#### Usando cross-validation determine el grado del polinomio que mejor describe la nube de puntos (encuentre el mejor balance entre apego a los datos de entrenamiento y generalización para datos previamente no observados)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, a través de Cross Validation se determinó que el mejor grado del polinomio es 5. Al realizar el respectivo modelo posteriormente con Descenso de Gradiente, se puede observar un mejor rendimiento a comparación de cuando se estaba usando el polinomio de grado 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El mejor grado de polinomio es: 5\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "# Determinar mejor grado de polinomio del 1 al 5\n",
    "polinomio_grado_accuracy = [[], [], [], [], []]\n",
    "\n",
    "for i in range(1, 6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=23)\n",
    "\n",
    "    sgd = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3)\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    # Cross Validation de SKLearn. Se le manda modelo entrenado con datos de training y también se manda\n",
    "    # datos de prueba para determinar rendimiento.\n",
    "    cross_val = cross_val_score(sgd, X_test, y_test, cv=5)\n",
    "\n",
    "    polinomio_grado_accuracy[i-1].append(i)\n",
    "    polinomio_grado_accuracy[i-1].append(cross_val.mean())\n",
    "\n",
    "# mostrar mejor grado de polinomio\n",
    "print('\\nEl mejor grado de polinomio es:', max(polinomio_grado_accuracy, key=lambda x: x[1])[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, al utilizar el grado de polinomio recomendado por Cross Validation se obtuvo un accuracy mayo de 77%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:  [[585 109]\n",
      " [218 526]]\n",
      "Accuracy del modelo: 0.7726008344923505\n"
     ]
    }
   ],
   "source": [
    "# Modelo logistico polinomial\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=23)\n",
    "\n",
    "# Crear el modelo\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "print('Matriz de confusión: ', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calcular la accuracy del modelo\n",
    "print('Accuracy del modelo:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## Tarea 1.5 \n",
    "#### Haga un análisis sobre sus hallazgos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
